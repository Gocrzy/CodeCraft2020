# 2020年华为软件精英挑战赛总结
## 写在前面
队名：守望&静望&观望，赛区：上合赛区

成绩：热身赛TOP100，初赛第五，复赛第二，决赛第二

参赛前，我们的心理预期是晋级复赛，没想到一路走到决赛，侥幸拿到亚军，能有这个成绩，离不开两位队友的努力，在此感谢他们，也特别感谢上合赛区的大佬们以及工作人员。
## 热身赛
我们热身赛做了两周，是在比赛中途参与进来的，都是常规思路，没有太多trick，这里简单讲一下思路。
### 训练集读取
* 只读部分训练数据（我们读了800行数据）
* 采用mmap读取，多进程并行读取（实测多进程快于多线程，可能是我们多线程没写好）
### 测试集读取
* 由于线上预测集特征都大于0，所以每行字符数相等，可用neon加速解码
* 采用mmap读取，多进程并行读取
### 训练
* 核心算法是 LR+Momentum
* 用neon指令做浮点数运算，实现加速
* 没有用多线程，因为当时初学多线程，并没有实现加速
### 预测
* 用neon指令做浮点数运算，实现加速
* 采用多进程并行计算
### 输出
* 由于当时使用open创建文件时，没有指定文件权限，导致线上编译失败，误以为线上不能用mmap写，因此改用fprintf写文件
* 写文件用时很短，所以没有采用多进程
## 初赛
### 数据读取
* mmap四进程并行读取
* 读取的id数据`id1`和`id2`放到共享内存数组`inputs`中
### 预处理
* `memcpy`将`inputs`中的有效数据拷贝到`input`中
* 线上数据的最大出度和入度均不超过50，因此可以对出边集和入边集开数组
* 线上数据的最大id不超过28万，可以直接用数组`idtoidx`保存id映射
* 线上数据参与构环的id小于50000，因此在存出入边时略掉大于`idMax`的id
* 四线程并行转换`idComma`,`idLF`,`idLen`，并对出入边排序，用`sprintf`函数转换为字符，neon指令拷贝
### 搜索
* 搜索算法采用4+3，即先反向搜索3层，保存所有路径到vector变量`PATH3`，并将符合条件的长度为3的环保存搭配`res3`，再正向搜索4层，第1层确定长为4的环，第2层确定长为5的环，第3层确定长为6的环，第4层确定长为7的环
* 搜索时，确保首节点id为最小，可以有效剪枝，且结果不会重复
* 这里环直接保存为字符串，并统计累积字符长度，方便在后面多进程输出
* 受热身赛影响，一直认为多进程比多线程快，所以搜索部分一直用多进程，但存在负载不均衡问题，只能针对线上数据调参
* 使用neon指令进行拷贝，要比`memcpy`快一点
* 正四层和反三层搜索全部for循环展开
### 结果输出
* 多进程mmap输出，由于结果已经存为字符串形式，并且统计了长度，因此可以方便地定位各进程的输出起点和终点
* 输出没用neon，实测在大内存块拷贝时`memcpy`更快
* 实测输出不必使用`wait`函数等待其它进程结束，并不影响结果
## 复赛
### 数据读取
* mmap四进程并行读取
* 每一行数据按出边和入边两种形式存到共享内存`Edge`数组中
* 金额使用int，与id构成pair<int,int>，可以提高cache命中率（A榜）
* B榜金额会出现三位小数，故将金额改成size_t，并放大1000倍（B榜）
### 预处理
* 先将`inputs`按id排序，将同一id的出边和入边放一块
* 由于线上数据不具有小id的特点，因此不能使用数组进行id转换，这里借助桶排序的概念，按id的高位和低位分别确定桶和桶内的位置
* 线上数据存在很大的出入度的节点，因此出入边采用前向星保存，均放到`shared_pool`中，`outedges`和`inedges`分别记录每个节点的起始地址，`outedgeSize`和`inedgeSize`分别记录对应的度数
* 直接开全局数组`shared_pool`（B榜），比`malloc`开数组读取更快
### 搜索
* A榜采用4+3双向搜索，B榜采用4+4（有同学指出线上5+3速度更快）
* 针对金额约束，在反三层搜索结束后，根据选择满足金额约束的正向第一层节点，在较多不满足金额约束的图中提升很大（线上提升小）
* `PATH3`改为数组，线上提升很大
* 改用多线程搜索，为了使用原子操作实现负载均衡
### 结果输出
* 输出采用五进程mmap，队友发现主进程分配少量任务，最后不等待其它子进程结束，线上会有提升（猜测计时只计主进程用时），因此主进程只输出长度为3和4的环（环数很少）
## 决赛
### 数据读取
* 和复赛一样，4进程mmap读取，虽然判题判题采用8U16G，但因为这部分时间几乎不影响最后成绩，所以也没改成8进程
* 由于0金额等效于无路径，因此读取时略去0金额转账数据
### 预处理
* 前部分处理和复赛B榜代码相同，后部分按照bfs的遍历顺序重新对节点id编号（因为后面搜索部分需要大量bfs，这里按bfs序编号节点可以提高cache命中）
* 针对稀疏图中存在大量入度为0，出度为1的节点，进行优化，预先标记这些节点为`head_node`，并标记关键节点为`key_node`（关键节点为子节点数大于1，父节点存在`head_node`），在搜索部分只处理剩余未标记节点和`key_node`节点即可（都放到`bag`数组中）
* 针对线上数据金额都小于255的特点，将`id`和`cash`构成`uint32_t`来存边，可以极大提高cache命中
### 搜索
* 核心算法采用 A Faster Algorithm for Betweenness Centrality（论文），时间复杂度为`O(n^2logn)`
* 由于线上dist不超过`uint16_t`，金额小且比较集中，heap可以采用手写的桶排序（特别感谢魔法少女的神奇堆思路），即push按照dist大小存取相应id，即array[dist]={id1,id2,...,idn},每次按照dist从小到大pop出当前最小dist对应id（最开始版本一次取一个id，取完对应dist的所有id，
再继续取下一个dist存的id）能以低复杂度实现优先队列（为了处理dist溢出，额外用手写二叉堆做备选切换）
* 针对节点前驱多数为1的特点，用`prev_info`来存每个节点的前驱节点，若有多于1的情况，切换到`shared_prev`保存（B榜从284提升到255）
* 使用桶排序的堆,每次使用完之后都要clear最大dist大小的记录每个dist对应id容量的数组，然而dist并不是连续，这个时候用memset可能可能会消耗额外时间（有些dist并没有用上,其容量数组并不需要clear），
我们改为一次从堆中提取每个dist对应的所有id，然后将相应下标为dist容量值清空，只清空用过的（B榜从255提升到251）.
* 当遇到起始节点是`key_node`时，可以一次计算出它前面的节点的所有`head_node`的中心性，利用了这些节点到`key_node`后面节点的路径数和`key_node`到后面节点的路径数一样的特点
### 结果输出
* 输出时间对最后成绩几乎没有影响，因此直接用`fwrite`单线成输出即可

